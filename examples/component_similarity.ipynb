{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf09ad3",
   "metadata": {},
   "source": [
    "# Examples of similarity pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cc954",
   "metadata": {},
   "source": [
    "## Feature extracting pipeline:\n",
    "Dataset is wildlife dataset\n",
    "Must have metadata attribute\n",
    "\n",
    "# FeatureDataset object\n",
    "- Features have features (iterable with len) and metadata (pandas df) properties with the same length.\n",
    "- metadata must have columns with label (unique identifier of label, eg string or int) and id (unique identifier of the datapoint,  eg string or int)\n",
    "\n",
    "There are three variants\n",
    "- Dataset of deep features - datapoint is fixed lengt vector\n",
    "- Dataset of images - datapoint is image tensor.\n",
    "- Dataset of local descriptors - datapoint is list of fixed lenght vectors.\n",
    "\n",
    "# Similarity pipeline:\n",
    "- similarity - N x M matrix, where N is length of query dataset and  M is lenght of database dataset.\n",
    "\n",
    "Resulting similarity object have additional two attributes:\n",
    "- metadata_query - dataframe with metadata inherited from query dataset\n",
    "- metadata_database - dataframe with metadata inherited from database dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c1c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import WildlifeDataset\n",
    "from torchvision import transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "root = 'examples/SampleDataset'\n",
    "metadata = pd.read_csv(f'{root}/metadata.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a057d",
   "metadata": {},
   "source": [
    "# Set of local descriptors\n",
    "\n",
    "- output is list of list with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ba252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.sift import SIFTFeatures\n",
    "from similarity.descriptor import DescriptorMatcher\n",
    "\n",
    "\n",
    "# Grayscale PIL images\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=256),\n",
    "    T.CenterCrop(size=(224, 224)),\n",
    "    T.Grayscale(),\n",
    "])\n",
    "dataset = WildlifeDataset(metadata, root=root, transform=transform)\n",
    "\n",
    "\n",
    "# Extract set of SIFT local descriptor for each image.\n",
    "extractor = SIFTFeatures()\n",
    "features = extractor(dataset)\n",
    "print('Shape')\n",
    "print([i.shape for i in features.features])\n",
    "print('Datapoint')\n",
    "print(features.features[0])\n",
    "\n",
    "\n",
    "# Similarity as number of correspondences below ratio test threshold\n",
    "similarity = MatchDescriptors(descriptor_dim=128, thresholds=[1e-5, 0.5, 0.9])\n",
    "similarity.match(features, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030773db",
   "metadata": {},
   "source": [
    "## Superpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2321bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.superpoint import SuperPointFeatures\n",
    "from similarity.descriptor import DescriptorMatcher\n",
    "\n",
    "\n",
    "# Dataset of Grayscale tensors\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=256),\n",
    "    T.CenterCrop(size=(224, 224)),\n",
    "    T.Grayscale(),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "dataset = WildlifeDataset(metadata, root=root, transform=transform)\n",
    "\n",
    "\n",
    "# Extract set of superpoint local descriptor for each image.\n",
    "extractor = SuperPointFeatures()\n",
    "features = extractor(dataset)\n",
    "print('Shape')\n",
    "print([i.shape for i in features.features])\n",
    "print('Datapoint')\n",
    "print(features.features[0])\n",
    "\n",
    "\n",
    "# Similarity as number of correspondences below ratio test threshold\n",
    "similarity = MatchDescriptors(descriptor_dim=256, thresholds=[1e-10, 0.5, 0.9])\n",
    "similarity(features, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0ea48",
   "metadata": {},
   "source": [
    "# Similarity pipeline using Deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce048f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.deep import DeepFeatures\n",
    "from similarity.cosine import CosineSimilarity\n",
    "import timm\n",
    "\n",
    "\n",
    "# Dataset of RGB tensors\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=256),\n",
    "    T.CenterCrop(size=(224, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "dataset = WildlifeDataset(metadata, root=root, transform=transform)\n",
    "\n",
    "\n",
    "# Extract deep features using pretrainend SWIN-T model from TIMM / HugginFace Hub\n",
    "extractor = DeepFeatures(model=timm.create_model('swin_tiny_patch4_window7_224', num_classes=0, pretrained=True))\n",
    "features = extractor(dataset)\n",
    "\n",
    "\n",
    "# Cosine similarity between deep features\n",
    "similarity = CosineSimilarity()\n",
    "similarity.calculate(features, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d37b9f",
   "metadata": {},
   "source": [
    "# Similarity pipeline using LOFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b1defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.40it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'LOFTRMatcher' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Similarity by number of LOFTR correspondences\u001b[39;00m\n\u001b[1;32m     21\u001b[0m matcher \u001b[38;5;241m=\u001b[39m LOFTRMatcher(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, thresholds\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.99\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m similarity\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LOFTRMatcher' object is not callable"
     ]
    }
   ],
   "source": [
    "from features.memory import InMemoryFeatures\n",
    "from similarity.loftr import LOFTRMatcher\n",
    "\n",
    "\n",
    "# Dataset of Grayscale tensors\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=256),\n",
    "    T.CenterCrop(size=(224, 224)),\n",
    "    T.Grayscale(),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "dataset = WildlifeDataset(metadata, root=root, transform=transform)\n",
    "\n",
    "\n",
    "# Loads image tensors to memory for faster access\n",
    "extractor = InMemoryFeatures()\n",
    "features = extractor(dataset)\n",
    "\n",
    "\n",
    "# Similarity by number of LOFTR correspondences\n",
    "similarity = MatchLOFTR(device='cpu', thresholds=[0.5, 0.9, 0.99])\n",
    "similarity.calculate(features, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635143a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f4838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b28a1d74",
   "metadata": {},
   "source": [
    "# Pipeline wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8eb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0acca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
